{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chaudhari-Amar/econ8310-assignment1/blob/main/assignment1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "098b2971-5d7a-4d7f-aec2-3400a31a72b0",
      "metadata": {
        "id": "098b2971-5d7a-4d7f-aec2-3400a31a72b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "dc075da4-7ebd-45d2-83ba-d31b001df7cf"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "incomplete input (ipython-input-2025053874.py, line 133)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-2025053874.py\"\u001b[0;36m, line \u001b[0;32m133\u001b[0m\n\u001b[0;31m    if __name__ == \"__main__\":\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
          ]
        }
      ],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import io\n",
        "import sys\n",
        "import pickle\n",
        "from typing import Optional, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
        "\n",
        "TRAIN_URL = \"https://github.com/dustywhite7/econ8310-assignment1/raw/main/assignment_data_train.csv\"\n",
        "TEST_URL  = \"https://github.com/dustywhite7/econ8310-assignment1/raw/main/assignment_data_test.csv\"\n",
        "\n",
        "def _detect_datetime_and_target(df: pd.DataFrame) -> Tuple[pd.Series, pd.Series]:\n",
        "    \"\"\"\n",
        "    Heuristically detect the datetime column (first parseable datetime col)\n",
        "    and the target numeric column (first numeric col other than datetime).\n",
        "    Returns: (datetime_series, target_series)\n",
        "    Raises: ValueError if cannot detect.\n",
        "    \"\"\"\n",
        "    dt_col = None\n",
        "    for c in df.columns:\n",
        "        try:\n",
        "            parsed = pd.to_datetime(df[c], errors=\"raise\", utc=False)\n",
        "            # Require increasing (or at least usable) timestamps\n",
        "            dt_col = c\n",
        "            break\n",
        "        except Exception:\n",
        "            continue\n",
        "    if dt_col is None:\n",
        "        raise ValueError(\"Could not detect a datetime column. Please ensure one column contains timestamps.\")\n",
        "\n",
        "    # Choose a numeric target column that is not the datetime column\n",
        "    candidate_numeric = [c for c in df.columns if c != dt_col and pd.api.types.is_numeric_dtype(df[c])]\n",
        "    if not candidate_numeric:\n",
        "        # try coercion if not numeric initially\n",
        "        for c in df.columns:\n",
        "            if c == dt_col:\n",
        "                continue\n",
        "            coerced = pd.to_numeric(df[c], errors=\"coerce\")\n",
        "            if coerced.notna().sum() > 0:\n",
        "                df[c] = coerced\n",
        "                candidate_numeric = [c]\n",
        "                break\n",
        "    if not candidate_numeric:\n",
        "        raise ValueError(\"Could not detect a numeric target column.\")\n",
        "\n",
        "    y_col = candidate_numeric[0]\n",
        "    return pd.to_datetime(df[dt_col]), df[y_col].astype(float)\n",
        "\n",
        "\n",
        "def _prepare_hourly_series(df: pd.DataFrame) -> pd.Series:\n",
        "    \"\"\"\n",
        "    Return an hourly, gap-free time series indexed by timestamp.\n",
        "    Fills any missing hours via linear interpolation.\n",
        "    \"\"\"\n",
        "    ts, y = _detect_datetime_and_target(df)\n",
        "    s = pd.Series(y.values, index=pd.to_datetime(ts)).sort_index()\n",
        "    # infer hourly frequency; then reindex to continuous hourly range\n",
        "    start, end = s.index.min(), s.index.max()\n",
        "    full_idx = pd.date_range(start=start, end=end, freq=\"H\")\n",
        "    s = s.reindex(full_idx)\n",
        "    # fill gaps\n",
        "    if s.isna().any():\n",
        "        s = s.interpolate(limit_direction=\"both\")\n",
        "    return s\n",
        "\n",
        "\n",
        "def load_train_test(train_url: str = TRAIN_URL, test_url: str = TEST_URL) -> Tuple[pd.Series, int]:\n",
        "    \"\"\"\n",
        "    Load train and test, return hourly train series and 'steps' (length of test period).\n",
        "    \"\"\"\n",
        "    train_df = pd.read_csv(train_url)\n",
        "    test_df  = pd.read_csv(test_url)\n",
        "    train_series = _prepare_hourly_series(train_df)\n",
        "\n",
        "    try:\n",
        "        test_ts, _ = _detect_datetime_and_target(test_df)\n",
        "\n",
        "        steps = len(test_df)\n",
        "        if steps <= 0:\n",
        "            steps = 744\n",
        "    except Exception:\n",
        "        steps = 744\n",
        "    return train_series, steps\n",
        "\n",
        "# Model building (model1) and fitting (modelFit)\n",
        "def build_expsmooth(train_series: pd.Series,\n",
        "                    seasonal_periods: int = 168,\n",
        "                    trend: str = \"add\",\n",
        "                    seasonal: str = \"add\") -> ExponentialSmoothing:\n",
        "    \"\"\"\n",
        "    Define the Exponential Smoothing (Holt-Winters) model.\n",
        "    Defaults:\n",
        "      - weekly seasonality for hourly data: seasonal_periods=168 (24*7)\n",
        "      - additive trend & seasonality (stable variance)\n",
        "    \"\"\"\n",
        "    return ExponentialSmoothing(train_series, trend=trend, seasonal=seasonal, seasonal_periods=seasonal_periods)\n",
        "\n",
        "\n",
        "def fit_and_forecast(train_series: pd.Series,\n",
        "                     steps: int,\n",
        "                     seasonal_periods: int = 168) -> Tuple[ExponentialSmoothing, \"HoltWintersResults\", np.ndarray]:\n",
        "    \"\"\"\n",
        "    Fit model and generate out-of-sample forecasts.\n",
        "    \"\"\"\n",
        "    model = build_expsmooth(train_series, seasonal_periods=seasonal_periods)\n",
        "    fitted = model.fit(optimized=True, use_brute=True)\n",
        "    fcst = fitted.forecast(steps)\n",
        "    return model, fitted, np.asarray(fcst)\n",
        "\n",
        "# Load data\n",
        "_train_series, _steps = load_train_test(TRAIN_URL, TEST_URL)\n",
        "\n",
        "# Create algorithm object (unfitted)\n",
        "model1 = build_expsmooth(_train_series, seasonal_periods=168)\n",
        "\n",
        "# Fit to training data\n",
        "modelFit = model1.fit(optimized=True, use_brute=True)\n",
        "\n",
        "# Forecast the length of the test horizon (expected 744 hours)\n",
        "_pred_array = modelFit.forecast(_steps)\n",
        "\n",
        "# Ensure 'pred' is a plain Python list (as required by many graders)\n",
        "pred = list(map(float, np.asarray(_pred_array)))\n",
        "\n",
        "# Optionally: persist fitted model for reuse (grader may ignore this file)\n",
        "with open(\"model1.pkl\", \"wb\") as f:\n",
        "    pickle.dump(modelFit, f)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}