{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chaudhari-Amar/econ8310-assignment1/blob/main/assignment1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === SINGLE-CELL COLAB SOLUTION (Corrected) ===\n",
        "# Model: Holt-Winters (Exponential Smoothing) with weekly seasonality (168 hours)\n",
        "\n",
        "!pip -q install statsmodels pandas numpy\n",
        "\n",
        "import warnings, pickle\n",
        "from typing import Tuple\n",
        "import numpy as np, pandas as pd\n",
        "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "TRAIN_URL = \"https://github.com/dustywhite7/econ8310-assignment1/raw/main/assignment_data_train.csv\"\n",
        "TEST_URL  = \"https://github.com/dustywhite7/econ8310-assignment1/raw/main/assignment_data_test.csv\"\n",
        "\n",
        "# ---- Helpers -----------------------------------------------------------------\n",
        "\n",
        "def _detect_timestamp_column(df: pd.DataFrame) -> str:\n",
        "    \"\"\"Return an existing timestamp-like column name if present, else ''.\"\"\"\n",
        "    cands = [c for c in df.columns if any(k in c.lower() for k in\n",
        "             [\"timestamp\",\"datetime\",\"date_time\",\"date time\",\"date\",\"time\"])]\n",
        "    return cands[0] if cands else \"\"\n",
        "\n",
        "def _build_datetime_from_parts(df: pd.DataFrame):\n",
        "    \"\"\"If the frame has separate year/month/day[/hour] columns, return a DatetimeIndex; else None.\"\"\"\n",
        "    cols = {c.lower(): c for c in df.columns}\n",
        "    need = {\"year\",\"month\",\"day\"}\n",
        "    if need.issubset(cols):\n",
        "        year, month, day = cols[\"year\"], cols[\"month\"], cols[\"day\"]\n",
        "        if \"hour\" in cols:\n",
        "            hour = cols[\"hour\"]\n",
        "            dt = pd.to_datetime(dict(year=df[year], month=df[month], day=df[day], hour=df[hour]), errors=\"coerce\")\n",
        "        else:\n",
        "            dt = pd.to_datetime(dict(year=df[year], month=df[month], day=df[day]), errors=\"coerce\")\n",
        "        return pd.DatetimeIndex(dt)\n",
        "    return None\n",
        "\n",
        "def _detect_target_column(df: pd.DataFrame, exclude=()) -> str:\n",
        "    \"\"\"\n",
        "    Prefer obvious trip/count names; otherwise choose a numeric column that's\n",
        "    not a date/time part (e.g., year/month/day/hour/weekday/week).\n",
        "    \"\"\"\n",
        "    preferred = ['trip_count','trips','trip','rides','ridership','count','target','y']\n",
        "    for key in preferred:\n",
        "        for c in df.columns:\n",
        "            if c not in exclude and key in c.lower():\n",
        "                return c\n",
        "\n",
        "    bad_exact = {'year','yr','month','day','date','hour','weekday','week','dow'}\n",
        "    numeric = [c for c in df.columns if c not in exclude and pd.api.types.is_numeric_dtype(df[c])]\n",
        "    numeric = [c for c in numeric if c.lower() not in bad_exact]\n",
        "    if numeric:\n",
        "        return numeric[0]\n",
        "\n",
        "    # last resort\n",
        "    return df.columns[-1]\n",
        "\n",
        "def _load(url: str) -> pd.DataFrame:\n",
        "    df = pd.read_csv(url)\n",
        "    # try a single timestamp column first\n",
        "    ts = _detect_timestamp_column(df)\n",
        "    if ts:\n",
        "        try:\n",
        "            df[ts] = pd.to_datetime(df[ts], errors=\"coerce\")\n",
        "        except Exception:\n",
        "            pass\n",
        "    # else try composing from parts\n",
        "    if not ts:\n",
        "        dt = _build_datetime_from_parts(df)\n",
        "        if isinstance(dt, pd.DatetimeIndex):\n",
        "            df.insert(0, \"constructed_ts\", dt)\n",
        "            ts = \"constructed_ts\"\n",
        "    # sort if we have a valid datetime\n",
        "    if ts and pd.api.types.is_datetime64_any_dtype(df[ts]):\n",
        "        df = df.sort_values(ts).reset_index(drop=True)\n",
        "    return df\n",
        "\n",
        "def _to_series(df: pd.DataFrame):\n",
        "    ts_col = _detect_timestamp_column(df)\n",
        "    if not ts_col and \"constructed_ts\" in df.columns:\n",
        "        ts_col = \"constructed_ts\"\n",
        "    y_col  = _detect_target_column(df, exclude=(ts_col,) if ts_col else ())\n",
        "\n",
        "    if ts_col and pd.api.types.is_datetime64_any_dtype(df[ts_col]):\n",
        "        idx = pd.DatetimeIndex(df[ts_col])\n",
        "        y = pd.Series(pd.to_numeric(df[y_col], errors=\"coerce\").astype(float).to_numpy(),\n",
        "                      index=idx, name=y_col)\n",
        "        return y, idx, ts_col, y_col\n",
        "    else:\n",
        "        y = pd.Series(pd.to_numeric(df[y_col], errors=\"coerce\").astype(float).to_numpy(), name=y_col)\n",
        "        return y, y.index, \"\", y_col\n",
        "\n",
        "def build_and_fit(y: pd.Series, seasonal_periods=168):\n",
        "    # Ensure non-negative support; shift if necessary.\n",
        "    vals = y.to_numpy()\n",
        "    min_y = float(np.nanmin(vals))\n",
        "    offset = 0.0\n",
        "    if min_y < 0:\n",
        "        offset = -min_y + 1e-6\n",
        "        y = y + offset\n",
        "\n",
        "    mdl = ExponentialSmoothing(\n",
        "        y.astype(float),\n",
        "        trend=\"add\",\n",
        "        seasonal=\"add\",\n",
        "        seasonal_periods=seasonal_periods,\n",
        "        initialization_method=\"estimated\"\n",
        "    )\n",
        "    res = mdl.fit(optimized=True, use_brute=True)\n",
        "    res._hw_offset = offset\n",
        "    return mdl, res\n",
        "\n",
        "def forecast_with_fitted(res, steps: int) -> np.ndarray:\n",
        "    fc = res.forecast(steps)\n",
        "    off = getattr(res, \"_hw_offset\", 0.0)\n",
        "    if off:\n",
        "        fc = np.asarray(fc) - off\n",
        "        fc = np.maximum(fc, 0.0)  # guard tiny negatives\n",
        "    return np.asarray(fc).ravel()\n",
        "\n",
        "# ---- Load, build, fit, forecast ---------------------------------------------\n",
        "\n",
        "train_df = _load(TRAIN_URL)\n",
        "test_df  = _load(TEST_URL)\n",
        "\n",
        "y_train, train_index, ts_train_col, y_train_col = _to_series(train_df)\n",
        "y_test,  test_index,  ts_test_col,  y_test_col  = _to_series(test_df)\n",
        "\n",
        "h = len(y_test) if len(y_test) > 0 else 744  # expected 744 hours for January\n",
        "\n",
        "# Required names for grading:\n",
        "model, modelFit = build_and_fit(y_train, seasonal_periods=168)\n",
        "pred = forecast_with_fitted(modelFit, h)\n",
        "\n",
        "# ---- Save artifacts ----------------------------------------------------------\n",
        "\n",
        "# Save fitted model (optional helper)\n",
        "try:\n",
        "    with open(\"model.pkl\", \"wb\") as f:\n",
        "        pickle.dump(modelFit, f)\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "# Save predictions CSV (with timestamps if we have them)\n",
        "if isinstance(test_index, pd.DatetimeIndex) and len(test_index) == h:\n",
        "    pd.DataFrame({\"timestamp\": test_index, \"prediction\": pred}).to_csv(\"predictions.csv\", index=False)\n",
        "else:\n",
        "    pd.DataFrame({\"t\": np.arange(h), \"prediction\": pred}).to_csv(\"predictions.csv\", index=False)\n",
        "\n",
        "# ---- Console summary ---------------------------------------------------------\n",
        "print(\"Columns (train):\", list(train_df.columns))\n",
        "print(f\"Detected timestamp column (train): {ts_train_col or 'None'}\")\n",
        "print(f\"Detected target column (train): {y_train_col}\")\n",
        "print(\"Training observations:\", len(y_train))\n",
        "print(\"Forecast horizon:\", h)\n",
        "print(\"First 5 predictions:\", pred[:5])\n",
        "\n",
        "# Auto-download in Colab (optional)\n",
        "try:\n",
        "    from google.colab import files\n",
        "    files.download(\"predictions.csv\")\n",
        "except Exception:\n",
        "    pass\n"
      ],
      "metadata": {
        "id": "laQXetkbTsnh",
        "outputId": "13f75983-7645-4928-9da9-8fdc7adb0375",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "id": "laQXetkbTsnh",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns (train): ['Timestamp', 'year', 'month', 'day', 'hour', 'trips']\n",
            "Detected timestamp column (train): Timestamp\n",
            "Detected target column (train): trips\n",
            "Training observations: 8760\n",
            "Forecast horizon: 744\n",
            "First 5 predictions: [5150.05941242 3027.62348696 2196.46342464 2005.68942901 2508.0126198 ]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_0ab21e29-c0d2-408b-8da6-d982a8d4d471\", \"predictions.csv\", 28501)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}